import pandas as pd
df = pd.read_csv('/Users/junnu/Downloads/Data Science /Assignment Questions/Naive Bayes and Text Mining/blogs_categories.csv')
df
print(df.head())
print(df.info())
print(df['Labels'].value_counts())
import seaborn as sns
import nltk
sns.countplot(y='Labels', data=df)
df['Cleaned_Text'] = df['Data'].str.lower()
df['Cleaned_Text'] = df['Cleaned_Text'].str.replace('[^\w\s]', '', regex=True)
import nltk
nltk.download('punkt')
nltk.download('stopwords')
  
from nltk.tokenize import word_tokenize
df['Tokenized_Text'] = df['Cleaned_Text'].apply(word_tokenize)

from nltk.corpus import stopwords
stop_words = set(stopwords.words('english'))
df['Filtered_Text'] = df['Tokenized_Text'].apply(lambda x: [word for word in x if word not in stop_words])

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf_vectorizer = TfidfVectorizer()
X_tfidf = tfidf_vectorizer.fit_transform(df['Filtered_Text'].apply(lambda x: ' '.join(x)))

from sklearn.model_selection import train_test_split
X = df['Cleaned_Text']  
y = df['Labels']         
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
text_clf = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('clf', MultinomialNB()),])
text_clf.fit(X_train, y_train)
y_pred = text_clf.predict(X_test)

from sklearn.metrics import classification_report, accuracy_score
print(classification_report(y_test, y_pred))
print("Accuracy:", accuracy_score(y_test, y_pred))

import nltk
nltk.download('vader_lexicon')
from nltk.sentiment import SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()
def get_sentiment(text):
    sentiment = sia.polarity_scores(text)
    if sentiment['compound'] > 0.05:
        return 'Positive'
    elif sentiment['compound'] < -0.05:
        return 'Negative'
    else:
        return 'Neutral'
df['Sentiment'] = df['Data'].apply(get_sentiment)

import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot( y='Sentiment', data=df)
plt.xticks(rotation=90)
plt.show()

sns.countplot(x='Labels', data=df)
plt.xticks(rotation=90)
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, average='weighted')
recall = recall_score(y_test, y_pred, average='weighted')
f1 = f1_score(y_test, y_pred, average='weighted')
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1-score:", f1)




























